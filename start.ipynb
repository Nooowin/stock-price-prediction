{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "207b8649-16e5-48dd-be08-93be96802f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c26abd06-b2c2-4414-a2e9-049255279283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#gonna start by manually copy and pasting some text from Seeking Alpha\n",
    "#gonna use NVDA\n",
    "ticker = \"NVDA\"\n",
    "start_date = \"2025-03-10\"\n",
    "end_date = \"2025-03-20\"\n",
    "nvda_data = yf.download(ticker, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b5e5e514-f550-4cab-ad58-0c1827803276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>NVDA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-03-10</th>\n",
       "      <td>106.970161</td>\n",
       "      <td>111.839709</td>\n",
       "      <td>105.450297</td>\n",
       "      <td>109.889891</td>\n",
       "      <td>366487400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-11</th>\n",
       "      <td>108.750000</td>\n",
       "      <td>112.229676</td>\n",
       "      <td>104.760361</td>\n",
       "      <td>106.980159</td>\n",
       "      <td>354865700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-12</th>\n",
       "      <td>115.739998</td>\n",
       "      <td>116.760002</td>\n",
       "      <td>112.879997</td>\n",
       "      <td>114.120003</td>\n",
       "      <td>323857500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-13</th>\n",
       "      <td>115.580002</td>\n",
       "      <td>117.760002</td>\n",
       "      <td>113.790001</td>\n",
       "      <td>117.029999</td>\n",
       "      <td>299033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-14</th>\n",
       "      <td>121.669998</td>\n",
       "      <td>121.879997</td>\n",
       "      <td>118.150002</td>\n",
       "      <td>118.610001</td>\n",
       "      <td>277593500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-17</th>\n",
       "      <td>119.529999</td>\n",
       "      <td>122.889999</td>\n",
       "      <td>118.029999</td>\n",
       "      <td>122.739998</td>\n",
       "      <td>255501500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-18</th>\n",
       "      <td>115.430000</td>\n",
       "      <td>119.019997</td>\n",
       "      <td>114.540001</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>299686900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-19</th>\n",
       "      <td>117.519997</td>\n",
       "      <td>120.449997</td>\n",
       "      <td>115.680000</td>\n",
       "      <td>117.269997</td>\n",
       "      <td>273426200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price            Close        High         Low        Open     Volume\n",
       "Ticker            NVDA        NVDA        NVDA        NVDA       NVDA\n",
       "Date                                                                 \n",
       "2025-03-10  106.970161  111.839709  105.450297  109.889891  366487400\n",
       "2025-03-11  108.750000  112.229676  104.760361  106.980159  354865700\n",
       "2025-03-12  115.739998  116.760002  112.879997  114.120003  323857500\n",
       "2025-03-13  115.580002  117.760002  113.790001  117.029999  299033100\n",
       "2025-03-14  121.669998  121.879997  118.150002  118.610001  277593500\n",
       "2025-03-17  119.529999  122.889999  118.029999  122.739998  255501500\n",
       "2025-03-18  115.430000  119.019997  114.540001  118.000000  299686900\n",
       "2025-03-19  117.519997  120.449997  115.680000  117.269997  273426200"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvda_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed90b97a-e2a1-4aba-a3cf-e703199cdd53",
   "metadata": {},
   "source": [
    "To calculate returns:\n",
    "\n",
    "return = (close_end - close_start) / close_start\n",
    "\n",
    "- can do multi-day returns or single day returns\n",
    "- will look at various metrics such as: volatility, return, volume\n",
    "\n",
    "| Window       | What It Captures           | Good For                                             |\n",
    "|--------------|----------------------------|------------------------------------------------------|\n",
    "| `t to t+1`   | Immediate next-day reaction | High-signal breaking news, overnight sentiment       |\n",
    "| `t to t+3`   | Short-term reaction         | Earnings reports, Fed statements, corporate events   |\n",
    "| `t to t+5`   | Full reaction cycle         | Captures delayed reactions, investor digestion       |\n",
    "| `t+1 to t+5` | Post-market sentiment       | Filters out pre-announcement speculation             |\n",
    "\n",
    "For this example, we are gonna capture short-term reaction, for this article: https://finance.yahoo.com/news/elon-musk-wanted-way-more-214202510.html\n",
    "\n",
    "We are gonna assume a publication was released after hours, unless otherwise specified, so start_date will be at t+1\n",
    "\n",
    "Also, we have to worry about weekends (the market is closed on weekends), so what do we do?\n",
    "Documentation here: https://pandas.pydata.org/docs/user_guide/timeseries.html \n",
    "\n",
    "- can use .offsets.BDay to add business days (excluding weekends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3a179102-f69f-4a4f-ad6d-d8148fed3c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2024-03-18 00:00:00')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker = \"NVDA\"\n",
    "publication_date = pd.to_datetime('2024-03-12')\n",
    "start_date = publication_date + pd.offsets.BDay(1)\n",
    "end_date = publication_date + pd.offsets.BDay(4)\n",
    "end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "011c3d20-508d-40c3-bd72-95e053ca4a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "ex_data = yf.download(ticker, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3c3f106d-a849-4900-b7f7-314758af87c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>NVDA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-03-13</th>\n",
       "      <td>90.858139</td>\n",
       "      <td>91.473934</td>\n",
       "      <td>88.405942</td>\n",
       "      <td>91.025084</td>\n",
       "      <td>635713000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-14</th>\n",
       "      <td>87.915108</td>\n",
       "      <td>90.616224</td>\n",
       "      <td>86.571548</td>\n",
       "      <td>89.547574</td>\n",
       "      <td>602318000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-15</th>\n",
       "      <td>87.808144</td>\n",
       "      <td>89.516582</td>\n",
       "      <td>86.228668</td>\n",
       "      <td>86.901444</td>\n",
       "      <td>642086000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price           Close       High        Low       Open     Volume\n",
       "Ticker           NVDA       NVDA       NVDA       NVDA       NVDA\n",
       "Date                                                             \n",
       "2024-03-13  90.858139  91.473934  88.405942  91.025084  635713000\n",
       "2024-03-14  87.915108  90.616224  86.571548  89.547574  602318000\n",
       "2024-03-15  87.808144  89.516582  86.228668  86.901444  642086000"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f74cb0f8-757e-45b5-a74a-17bfaaede82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_return(ending_price, starting_price):\n",
    "    return (ending_price - starting_price) / starting_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3136562c-3493-4043-b139-f658c1313bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-2.1397922180365336)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate returns\n",
    "close_price_end = ex_data.iloc[-1][('High', 'NVDA')]\n",
    "close_price_start = ex_data.iloc[0][('High', 'NVDA')]\n",
    "calc_return(close_price_end, close_price_start) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "97cce034-944c-4115-871e-03a32ad963bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://finance.yahoo.com/news/elon-musk-wanted-way-more-214202510.html\"\n",
    "response = requests.get(url, headers = {\"User-Agent\": \"Mozilla/5.0\"})\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "article_block = soup.find_all(\"p\", class_ = \"yf-1090901\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8303f197-80df-4fe4-bfb2-0d146809dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = [p.get_text() for p in article_block]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9bf11e04-42ee-4314-ba16-693a982d28d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nvidia stock has tripled this year as investors bet the AI boom will fuel demand for graphics chips.',\n",
       " \"Oracle's Larry Ellison said Elon Musk's xAI wanted more Nvidia chips than it could offer last quarter.\",\n",
       " 'Oracle is spending heavily on scaling up to meet intense demand from clients like Musk.',\n",
       " \"Nvidia stock has more than tripled this year as investors bet the graphics-chip specialist will power the artificial-intelligence revolution. Elon Musk is among those who can't get enough of its semiconductors, Oracle's Larry Ellison said on Monday.\",\n",
       " \"Musk has opted to use Oracle's servers to run his xAI company's recently launched chatbot, Grok. The cloud-infrastructure giant managed to provide enough Nvidia chips to power the first version of Grok, but fell short of Musk's demands, Ellison said during Oracle's latest earnings call, according to a transcript provided by AlphaSense/Sentieo.\",\n",
       " '\"Boy, did they want a lot more GPUs than we gave them,\" Oracle\\'s billionaire cofounder and tech chief said. \"We gave them quite a few but they wanted more, and we are in the process of getting them more.\"',\n",
       " '\"They were able to use it, but they want dramatically more as there\\'s this gold rush towards building the world\\'s greatest large language model,\" Ellison, one of Tesla\\'s biggest shareholders, continued. \"And we are doing our best to give our customers what we can this quarter, and then dramatically increase our ability to give them more and more capacity each succeeding quarter.\"',\n",
       " \"Ellison gave the example of xAI after a Wall Street analyst questioned Oracle's plans to build 100 new cloud data centers, up from around 66 today. Ellison noted that Microsoft alone has ordered 20 data centers to support its Azure cloud-computing platform, and Oracle wants to build many others to meet demand from its direct customers.\",\n",
       " 'Oracle CEO Safra Catz struck a similar tone, saying that the company held back last quarter to make sure it could provide larger-scale services going forward. There was \"hundreds of millions of dollars\" waiting to be scooped up, she said, but Oracle left it on the table so it could focus on building capacity \"because we need more and we need it bigger.\"',\n",
       " \"Musk has been loading up on Nvidia chips for his companies for a while now. Business Insider's Kali Hays reported in April that he had purchased 10,000 graphics processors for xAI. The Tesla CEO also said on an earnings call in July that the EV maker was buying as many as it could.\",\n",
       " '\"We\\'re using a lot of Nvidia hardware,\" he said. \"We\\'ll actually take it as fast as they\\'ll deliver it to us. Frankly, if they could deliver us enough GPUs, we might not need Dojo. But they can\\'t. They\\'ve got so many customers.\"',\n",
       " \"Ellison's latest comment about Musk and xAI suggests demand for graphics chips remains intense, which is welcome news for Nvidia investors.\",\n",
       " 'Read the original article on Business Insider']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "ea3b6b5f-b41f-48f1-bb28-aa3f72623bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nvidia stock has tripled this year as investors bet the ai boom will fuel demand for graphics chips ',\n",
       " \"oracle's larry ellison said elon musk's xai wanted more nvidia chips than it could offer last quarter \",\n",
       " 'oracle is spending heavily on scaling up to meet intense demand from clients like musk ',\n",
       " \"nvidia stock has more than tripled this year as investors bet the graphics chip specialist will power the artificial intelligence revolution elon musk is among those who can't get enough of its semiconductors oracle's larry ellison said on monday \",\n",
       " \"musk has opted to use oracle's servers to run his xai company's recently launched chatbot grok the cloud infrastructure giant managed to provide enough nvidia chips to power the first version of grok but fell short of musk's demands ellison said during oracle's latest earnings call according to a transcript provided by alphasense sentieo \",\n",
       " \" boy did they want a lot more gpus than we gave them oracle's billionaire cofounder and tech chief said we gave them quite a few but they wanted more and we are in the process of getting them more \",\n",
       " \" they were able to use it but they want dramatically more as there's this gold rush towards building the world's greatest large language model ellison one of tesla's biggest shareholders continued and we are doing our best to give our customers what we can this quarter and then dramatically increase our ability to give them more and more capacity each succeeding quarter \",\n",
       " \"ellison gave the example of xai after a wall street analyst questioned oracle's plans to build 100 new cloud data centers up from around 66 today ellison noted that microsoft alone has ordered 20 data centers to support its azure cloud computing platform and oracle wants to build many others to meet demand from its direct customers \",\n",
       " 'oracle ceo safra catz struck a similar tone saying that the company held back last quarter to make sure it could provide larger scale services going forward there was hundreds of millions of dollars waiting to be scooped up she said but oracle left it on the table so it could focus on building capacity because we need more and we need it bigger ',\n",
       " \"musk has been loading up on nvidia chips for his companies for a while now business insider's kali hays reported in april that he had purchased 10 000 graphics processors for xai the tesla ceo also said on an earnings call in july that the ev maker was buying as many as it could \",\n",
       " \" we're using a lot of nvidia hardware he said we'll actually take it as fast as they'll deliver it to us frankly if they could deliver us enough gpus we might not need dojo but they can't they've got so many customers \",\n",
       " \"ellison's latest comment about musk and xai suggests demand for graphics chips remains intense which is welcome news for nvidia investors \",\n",
       " 'read the original article on business insider']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [re.sub(r\"[^A-Za-z0-9']+\", ' ', line) for line in paragraphs]\n",
    "text = list(map(str.lower, text))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "85dacfa4-2b8d-4ba3-9b87-9969e3bdd87c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"nvidia stock has tripled this year as investors bet the ai boom will fuel demand for graphics chips  oracle's larry ellison said elon musk's xai wanted more nvidia chips than it could offer last quarter  oracle is spending heavily on scaling up to meet intense demand from clients like musk  nvidia stock has more than tripled this year as investors bet the graphics chip specialist will power the artificial intelligence revolution elon musk is among those who can't get enough of its semiconductors oracle's larry ellison said on monday  musk has opted to use oracle's servers to run his xai company's recently launched chatbot grok the cloud infrastructure giant managed to provide enough nvidia chips to power the first version of grok but fell short of musk's demands ellison said during oracle's latest earnings call according to a transcript provided by alphasense sentieo   boy did they want a lot more gpus than we gave them oracle's billionaire cofounder and tech chief said we gave them quite a few but they wanted more and we are in the process of getting them more   they were able to use it but they want dramatically more as there's this gold rush towards building the world's greatest large language model ellison one of tesla's biggest shareholders continued and we are doing our best to give our customers what we can this quarter and then dramatically increase our ability to give them more and more capacity each succeeding quarter  ellison gave the example of xai after a wall street analyst questioned oracle's plans to build 100 new cloud data centers up from around 66 today ellison noted that microsoft alone has ordered 20 data centers to support its azure cloud computing platform and oracle wants to build many others to meet demand from its direct customers  oracle ceo safra catz struck a similar tone saying that the company held back last quarter to make sure it could provide larger scale services going forward there was hundreds of millions of dollars waiting to be scooped up she said but oracle left it on the table so it could focus on building capacity because we need more and we need it bigger  musk has been loading up on nvidia chips for his companies for a while now business insider's kali hays reported in april that he had purchased 10 000 graphics processors for xai the tesla ceo also said on an earnings call in july that the ev maker was buying as many as it could   we're using a lot of nvidia hardware he said we'll actually take it as fast as they'll deliver it to us frankly if they could deliver us enough gpus we might not need dojo but they can't they've got so many customers  ellison's latest comment about musk and xai suggests demand for graphics chips remains intense which is welcome news for nvidia investors  read the original article on business insider\""
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text= \" \".join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "93229c63-fe89-4e01-8c5f-0bc445c71896",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"yiyanghkust/finbert-tone\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "09826d4d-91bb-416d-bb92-ed5501938665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5f941ec1-3509-4dbe-94f2-c1bbc67c78c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (572) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[236], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/pipelines/text_classification.py:159\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03mClassify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (inputs,)\n\u001b[0;32m--> 159\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/pipelines/base.py:1371\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1364\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1365\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1368\u001b[0m         )\n\u001b[1;32m   1369\u001b[0m     )\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/pipelines/base.py:1378\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1377\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1378\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/pipelines/base.py:1278\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1277\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1278\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1279\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/pipelines/text_classification.py:190\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    189\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/bert/modeling_bert.py:1673\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1667\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1669\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1673\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1679\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1680\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1683\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1685\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1687\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/bert/modeling_bert.py:1078\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1076\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m-> 1078\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1087\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((batch_size, seq_length \u001b[38;5;241m+\u001b[39m past_key_values_length), device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/bert/modeling_bert.py:217\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    216\u001b[0m     position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embeddings(position_ids)\n\u001b[0;32m--> 217\u001b[0m     embeddings \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[1;32m    218\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(embeddings)\n\u001b[1;32m    219\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(embeddings)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (572) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "result = classifier(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bab974-b504-4e77-9a20-8bae692fd205",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f538088-4a9d-4c34-b545-074f62296638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
